<html>
<head>
<title>File and Back end System Status</title>
<style>table {border: 1px solid black;}
</style>
</head>
<body>
<table width='80%' align='center'>
<tr><td align="center"><h3>Content Management System (CoMS)</h3><br></td></tr>
<tr><td><h4>Overview:</h4><br></td></tr>
<tr><td><p>Content Management System is used to process, aggregate and manage the content of the products.
 It provides various input sources as email, ftp, bulk upload or API json. Vendor can use any of the mechanism 
 to upload the content which is used by CaMS(Catalog Management System) and IPMS(Inventory & Pricing Management System).
 A Unique ID-SUPC is given to each product to uniquely identify it.</p><br></td></tr>
 <tr><td><h4>Architecture:</h4><br></td></tr>
 
 <tr><td><p>Below is the Architectural Representation of COMS.</p><br></td></tr>
 <tr><td><img src="image/image2015-10-12 15-10-17.png"/><br></td></tr>
 <tr><td><p><strong>CoMS Components:</strong> There are three Components which describes the flow of data from CoMS.</p><br></td></tr>
 <tr><td><p><strong>1. Core:</strong> updates product processed from file and sends the mail to the login user about the status via UMS(User Management System).
 Core Component also updates Mongo DB with the status and after successful processing; 
 Core sends a mail to the user via UMS with Upload id details on every successful or un-successful uploads. 
 Core updates product processed from file and after successful processing puts the message 
 for inventory pricing updates on ActiveMQ(message broker).</p><br></td></tr>
<tr><td><p><strong>Tables Involved: </strong>feed_session_info</p><br></td></tr>
<tr><td><p><strong>2. Aggregator </strong>picks vendor product updates from Mongo whose flag is set to true and generates SUPC. 
The generated SUPC are stored in the supc_product_mapping table (COMSDB). 
Aggregator send another mail to Seller(user) with generated SUPC via UMS.</p><br></td></tr>
<tr><td><p><strong>Tables Involved: </strong>supc and supc_product_mapping</p><br></td></tr>
<tr><td><p><strong>3. Publisher </strong>fetches the created SUPC generated by aggregator. Publisher will push data into below systems:</p><br></td></tr>
<tr><td><p><strong>CaMS:</strong>If catalog is created for the first time (new Products), CATALOG-CREATION-EVENT published on Active MQ and an entry is populated 
in catalog_workflow table on successful creation of catalog (CaMS).</p><br></td></tr>
<tr><td><p><strong>Shipping:</strong> Once new catalog being created Shipping will also be created for that which is having product information like wieght, 
length, breadth, height, is fragile, etc and an entry is populated in shipping_catalog table on successful creation.</p><br></td></tr>
<tr><td><p><strong>Score: </strong>Rating given to seller based on fulfillment of orders. Score is maintaining same details as Shipping system and on successful 
creation one entry get populated in score_workflow table.</p><br></td></tr>
<tr><td><p><strong>On_Failure: </strong>On failure of creation of catalog or shipping Publisher will send another mail to Seller via UMS.</p><br></td></tr>
<tr><td><p><strong>IPMS: </strong>Publisher gets five different channel requests for IPMS i.e. IPMS_Inventory, IPMS_Pricing, IPMS_Freebie, IPMS_PVPM and OPS from Core via 
ActiveMQ to process and populate all these informations into IPMS.</p><br></td></tr>
<tr><td><p><strong>Priority Queuing in COMS : </strong>Post September 2015 COMS has added the functionality to Prioritize uploads if needed.This functionality is added to ensure faster listing in Case of dpendency. </p><br></td></tr>
<tr><td><p><strong>Log Path: /var/lib/coms/logs</strong></p><td></tr>
<tr><td><p><strong>Tables Involved: </strong>catalog_workflow, shipping_workflow, score_workflow, supc_error_state<br>
<strong>Database: </strong>Database used in CoMS is comsdb.<br>
<strong>Relavent Tables used in comsdb:</strong><br>
</p><br></td></tr>
<tr><td><p><strong>1. vendor: </strong>This table is having seller details like sellor code, name, email id, seller status(enabled or disabled),
 etc. If seller is not enabled, raise it with CRM team(SalesForce).</p><br></td></tr>
 <tr><td><p><strong>2.feed_session_info: </strong>Stores session details related to feeds. Once feed file is upload into the system, one upload id corresponding each file get stored here. 
 Also on un-successful upload error state is getting stored in this table.</p><br></td></tr>
 <tr><td><p><strong>3. supc: </strong>Stores details of snapdeal unique product code.</p><br></td></tr>
 <tr><td><p><strong>4. supc_product_mapping: </strong>Stores mapped result of the supc with product. SUPC generated by aggegator are stored here. This table also having vendor sku, vendor id and upload id for product creation request at first place. There is no updates in this table for already 
 extsting products where sellers are updating inventory and pricing details</p><br></td></tr>
 <tr><td><p><strong>5. supc_error_state: </sttrong> This table stores errors appeared at the time of sending information to CaMS and also notified via email.</p><br></td></tr>
 <tr><td><p><strong>6. category_workflow: </strong>Once Catalog created in CaMS successfully. This table got populated.</p><br></td></tr>
 <tr><td><p><strong>7. shipping_workflow: </strong>Once Shipping details created successfully. This table got populated.</p></dt></tr>
 <tr><td><p><strong>8. score_workflow: </strong>Once Score details created successfully. This table got populated.</p><br></td></tr>
 <tr><td><p><strong>Logging: </strong>As part of CoMS, different log files are getting generated for each component. Please find below path specific to each component:</p><br></td></tr>
 <tr><td><p><strong>Core log: </strong>/var/lib/coms/logs/coms-core/coms-core.log</p><br></td></tr>
 <tr><td><p><strong>Aggregator log: </strong>/var/lib/coms/logs/coms-aggregator/coms-aggregator.log</p><br></td></tr>
 <tr><td><p><strong>Publisher log: </strong>/var/lib/coms/logs/coms-publisher/coms-publisher.log</p><br></td></tr>
 <tr><td><p><strong>Publisher kafka logs: </strong> /var/lib/coms/logs/coms-publisher/coms-publisher-kafka.log</p><br></td></tr>
 <tr><td><p><strong>New Product Creation Life Cycle :</strong></p><br></td></tr>
 <tr><td><img src="image/bulk_upload_process.jpg" /><br></td></tr>
 <tr><td><p><strong>Product Creation States :</strong></p><br></td></tr>
 <tr><td><img src="image/bulk_upload_states.jpg" /><br></td></tr>
</table>
</body>
</html>
